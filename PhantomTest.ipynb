{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow ( we will use keras from tensorflow)\n",
    "import tensorflow\n",
    "\n",
    "# Load Keras\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Input, Dense, Conv3D, Flatten, Reshape, MaxPool3D, UpSampling3D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Utilities\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "class mygenerator(Sequence):\n",
    "    def __init__(self, obj, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.num_samples = obj[self.x].shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.num_samples/float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = h5py.File('/data/Phantom/data.h5','r')\n",
    "\n",
    "        # read your data here using the batch lists, batch_x and batch_y\n",
    "        \n",
    "        x = data[self.x][idx*self.batch_size:(idx+1)*self.batch_size,...]\n",
    "        y = data[self.y][idx*self.batch_size:(idx+1)*self.batch_size,...][...,np.newaxis]\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build functional model\n",
    "inputs = Input(shape=(128, 128, 16, 126),dtype='float32')\n",
    "init = 'he_normal'\n",
    "base_filters = 126\n",
    "convolutions_per_layer = 4\n",
    "\n",
    "x = Conv3D(base_filters,kernel_size=(3,3,3),\n",
    "           padding='same',\n",
    "           activation='relu',\n",
    "           kernel_initializer=init)(inputs)\n",
    "\n",
    "\n",
    "# Attach a conv encoder\n",
    "for i in range(convolutions_per_layer):\n",
    "    x = Conv3D(base_filters,kernel_size=(3,3,3),\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               kernel_initializer=init)(x)\n",
    "    \n",
    "\n",
    "\n",
    "# Save this shortcut to make training a bit easier\n",
    "shortcut = x\n",
    "x = MaxPool3D(pool_size=(2,2,2), strides=None, padding='valid')(x)\n",
    "for i in range(convolutions_per_layer):\n",
    "    x = Conv3D(2*base_filters,kernel_size=(3,3,3),\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               kernel_initializer=init)(x)\n",
    "    \n",
    "x = MaxPool3D(pool_size=(2,2,2), strides=None, padding='valid')(x)\n",
    "\n",
    "for i in range(convolutions_per_layer):\n",
    "    x = Conv3D(3*base_filters,kernel_size=(3,3,3),\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               kernel_initializer=init)(x)\n",
    "    \n",
    "x = MaxPool3D(pool_size=(2,2,2), strides=None, padding='valid')(x)\n",
    "\n",
    "for i in range(convolutions_per_layer):\n",
    "    x = Conv3D(4*base_filters,kernel_size=(3,3,3),\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               kernel_initializer=init)(x)\n",
    "\n",
    "'''  Image Here is Encoded'''\n",
    "for i in range(convolutions_per_layer):\n",
    "    x = Conv3D(3*base_filters,kernel_size=(3,3,3),\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               kernel_initializer=init)(x)\n",
    "    \n",
    "x = UpSampling3D(size=(2,2,2))(x)\n",
    "\n",
    "for i in range(convolutions_per_layer):\n",
    "    x = Conv3D(2*base_filters,kernel_size=(3,3,3),\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               kernel_initializer=init)(x)\n",
    "\n",
    "x = UpSampling3D(size=(2,2,2))(x)\n",
    "for i in range(convolutions_per_layer):\n",
    "    x = Conv3D(base_filters,kernel_size=(3,3,3),\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               kernel_initializer=init)(x)\n",
    "\n",
    "x = UpSampling3D(size=(2,2,2))(x)\n",
    "\n",
    "\n",
    "\n",
    "#Add a shortcut\n",
    "x = tensorflow.keras.layers.Concatenate()([x, shortcut])\n",
    "\n",
    "predictions = Conv3D(1,kernel_size=(1,1,1),activation='linear',kernel_initializer=init)(x)\n",
    "\n",
    "# Setup optimizer\n",
    "adam = tensorflow.keras.optimizers.Adam(lr=0.00001)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer=adam, loss='mean_squared_error')\n",
    "\n",
    "# Print a summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    This is a traing callback that the fitting algorithm will run during training\n",
    "'''\n",
    "class TraingCallback(tensorflow.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.fig = plt.figure(figsize=(10,3))\n",
    "        self.logs = []\n",
    "        self.floor_epoch = 0\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    #def on_train_end( self, logs={}):\n",
    "        # Do nothing\n",
    "\n",
    "    #def on_batch_begin(self, batch, logs={}): \n",
    "        # Do nothing \n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "\n",
    "        if batch%10==0:\n",
    "            self.losses.append(logs.get('loss'))\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            self.fig = plt.figure(figsize=(10,3))\n",
    "\n",
    "\n",
    "            # self.params\n",
    "            #{'verbose': 1, 'nb_epoch': 12, 'batch_size': 128, 'metrics': ['loss', 'acc', 'val_loss', 'val_acc'], 'nb_sample': 60000, 'do_validation': True}\n",
    "            batch_size = self.params['batch_size']\n",
    "            data = h5py.File('/data/Phantom/data.h5','r')\n",
    "\n",
    "\n",
    "            '''\n",
    "                Run a test case\n",
    "            '''\n",
    "            # Test with above image\n",
    "            testim = data['Train_X'][0,...][np.newaxis,...]\n",
    "            predicted_image = model.predict(x=testim)\n",
    "            plt.subplot(132)\n",
    "            predicted_slice = np.squeeze(predicted_image)\n",
    "            plt.imshow(predicted_slice[...,8], cmap='gray',vmin=0,vmax=1)\n",
    "            plt.title('Predicted Image')\n",
    "            plt.axis('off')\n",
    "\n",
    "            testout = data['Train_Y'][0,...][...,np.newaxis]\n",
    "            plt.subplot(133)\n",
    "            plt.imshow(testout[...,8,0],cmap='gray',vmin=0,vmax=1)\n",
    "            plt.title('True Image')\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Using just this one image to get a loss\n",
    "            self.val_losses.append( model.evaluate(x=testim,y=testout[np.newaxis,...],verbose=False))\n",
    "\n",
    "            '''\n",
    "            Plot the Losses \n",
    "            '''\n",
    "            plt.subplot(131)\n",
    "            plt.semilogy(self.losses, label=\"Loss\")\n",
    "            plt.semilogy(self.val_losses, label=\"Loss (test image)\")\n",
    "            plt.legend()\n",
    "\n",
    "            print('Epoch = ' + str(self.floor_epoch) + 'Loss = ' + str(logs.get('loss')) )\n",
    "            plt.show();\n",
    "\n",
    "    def on_epoch_begin(self,epoch,logs={}):\n",
    "        self.floor_epoch = epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "epochs=40\n",
    "\n",
    "\n",
    "data = h5py.File('/data/Phantom/data.h5','r')\n",
    "train_gen = mygenerator(data,'Train_X','Train_Y',batch_size)\n",
    "val_gen = mygenerator(data,'Val_X','Val_Y',batch_size)\n",
    "\n",
    "training_callback = TraingCallback()\n",
    "\n",
    "model.fit_generator(generator=train_gen,\n",
    "          validation_data=val_gen,\n",
    "          epochs=epochs,\n",
    "          callbacks=[training_callback],\n",
    "          verbose=False\n",
    "         );\n",
    "\n",
    "model.save(\"TestModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testim = x_val[0,...][np.newaxis,...]\n",
    "output = model.predict(testim)\n",
    "plt.imshow(output[0,:,:,8,0])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(y_val[0,...,8,0])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testim = x_val[0,...][np.newaxis,...]\n",
    "predicted_image = model.predict(x=testim)\n",
    "predicted_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
